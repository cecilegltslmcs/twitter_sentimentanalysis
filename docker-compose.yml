version: '3.9'

services:
    kafka:
        container_name: kafka
        build:
            context: .
            dockerfile: kafka_components/Dockerfile_kafka.yaml
    spark:
        image: cluster-apache-spark:3.0.2
        ports:
           - "9090:8080"
           - "7077:7077"
        volumes:
           - ./apps:/opt/spark-apps
           - ./data:/opt/spark-data
        environment:
           - SPARK_LOCAL_IP=spark-master
           - SPARK_WORKLOAD=master
    spark-worker-a:
        image: cluster-apache-spark:3.0.2
        ports:
           - "9091:8080"
           - "7000:7000"
        depends_on:
           - spark-master
        environment:
            - SPARK_MASTER=spark://spark-master:7077
            - SPARK_WORKER_CORES=1
            - SPARK_WORKER_MEMORY=1G
            - SPARK_DRIVER_MEMORY=1G
            - SPARK_EXECUTOR_MEMORY=1G
            - SPARK_WORKLOAD=worker
            - SPARK_LOCAL_IP=spark-worker-a
        volumes:
            - ./apps:/opt/spark-apps
            - ./data:/opt/spark-data
    spark-worker-b:
        image: cluster-apache-spark:3.0.2
        ports:
            - "9092:8080"
            - "7001:7000"
        depends_on:
            - spark-master
        environment:
            - SPARK_MASTER=spark://spark-master:7077
            - SPARK_WORKER_CORES=1
            - SPARK_WORKER_MEMORY=1G
            - SPARK_DRIVER_MEMORY=1G
            - SPARK_EXECUTOR_MEMORY=1G
            - SPARK_WORKLOAD=worker
            - SPARK_LOCAL_IP=spark-worker-b
        volumes:
            - ./apps:/opt/spark-apps
            - ./data:/opt/spark-data
    mongodb:
         container_name: mongo
         image: mongo
         restart: always
         ports:
             - "27017:27017"
         environment:
             MONGO_INITDB_ROOT_USERNAME: root
             MONGO_INITDB_ROOT_PASSWORD: example
    streamlit:
        container_name: streamlit
        build:
            context: .
            dockerfile: dashboard/Dockerfile_dashboard